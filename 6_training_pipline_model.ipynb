{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTdXh/EGtb0A4+2Dh3vQcD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nizardbsk/pl_pytorch_tutorial/blob/main/6_training_pipline_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE2k-prxe2ZQ",
        "outputId": "5b8c1658-0e14-46f8-a4e7-57975b882aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Prediction before training : f(5) = 4.391\n",
            "epoch 1: w = 0.876, loss = 7.87994242\n",
            "epoch 3: w = 1.110, loss = 3.89337015\n",
            "epoch 5: w = 1.273, loss = 1.97277880\n",
            "epoch 7: w = 1.386, loss = 1.04690480\n",
            "epoch 9: w = 1.466, loss = 0.59996831\n",
            "epoch 11: w = 1.522, loss = 0.38363940\n",
            "epoch 13: w = 1.561, loss = 0.27835423\n",
            "epoch 15: w = 1.589, loss = 0.22654641\n",
            "epoch 17: w = 1.609, loss = 0.20049955\n",
            "epoch 19: w = 1.624, loss = 0.18686871\n",
            "Prediction after training : f(5) = 9.159\n"
          ]
        }
      ],
      "source": [
        "# 1) Design model (input,output size,forward pass)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#   - forward pass : compute prediction\n",
        "#   - backward pass : gradients\n",
        "#   - update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor([[5]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "in_size = n_features\n",
        "out_size = n_features\n",
        "#model = nn.Linear(in_size,out_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self,input_dim,out_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.lin = nn.Linear(input_dim,out_dim)\n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(in_size,out_size)\n",
        "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "  if epoch % 2 ==0:\n",
        "    [w,b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {model(X_test).item():.3f}')"
      ]
    }
  ]
}